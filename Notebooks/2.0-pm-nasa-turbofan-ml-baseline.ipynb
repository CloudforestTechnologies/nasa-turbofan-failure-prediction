{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "# Module Importations\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Module Versioning\n",
    "print(sklearn.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Modules\n",
    "from Source.Data import ntfp_dataset_import as data_load\n",
    "from Source.Data import ntfp_split_data as split_data\n",
    "from Source.Features import ntfp_dataset_preprocessing as preprocessing\n",
    "from Source.Model import ntfp_model_evaluation as evaluation\n",
    "from Source.Model import ntfp_sklearn_helpers as sklearn_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\nLoading pickled dataframe complete ...\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 20631 entries, 1 to 100\nData columns (total 14 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Cycles  20631 non-null  int64  \n 1   Sn_02   20631 non-null  float64\n 2   Sn_03   20631 non-null  float64\n 3   Sn_04   20631 non-null  float64\n 4   Sn_07   20631 non-null  float64\n 5   Sn_09   20631 non-null  float64\n 6   Sn_11   20631 non-null  float64\n 7   Sn_12   20631 non-null  float64\n 8   Sn_14   20631 non-null  float64\n 9   Sn_15   20631 non-null  float64\n 10  Sn_17   20631 non-null  int64  \n 11  Sn_20   20631 non-null  float64\n 12  Sn_21   20631 non-null  float64\n 13  RUL     20631 non-null  float64\ndtypes: float64(12), int64(2)\nmemory usage: 2.4 MB\nNone\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "data_filename = 'rul_dataset.pkl'\n",
    "rul_df = data_load.load_pickled_data(data_filename)\n",
    "\n",
    "print(rul_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-1.72172539 -0.13425518 -0.92593596 ... -0.78170979  1.34849274\n   1.19442705]\n [-1.06177971  0.21152849 -0.64372587 ... -0.78170979  1.01652793\n   1.23692196]\n [-0.66181262 -0.41316559 -0.52595315 ... -2.07309423  0.73989059\n   0.50342281]\n ...\n [ 1.47801126  1.94697106  2.13837684 ...  3.09244354 -2.08181033\n  -3.29248147]\n [ 1.09804254  2.40366648  1.95505138 ...  1.15536688 -2.91172236\n  -2.08507166]\n [ 2.33794049  1.60771161  2.57835793 ...  1.8010591  -2.46910261\n  -2.19408035]]\nShape: (20631, 12)\n"
     ]
    }
   ],
   "source": [
    "# Normalise columns into array\n",
    "normalised_array = preprocessing.standardise_columns(rul_df)\n",
    "\n",
    "print(normalised_array)\n",
    "print(\"Shape:\", normalised_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            Sn_02       Sn_03       Sn_04       Sn_07       Sn_09       Sn_11  \\\ncount  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \nmean     0.010975    0.010625    0.012324   -0.011917    0.007100    0.012641   \nstd      0.002842    0.002459    0.003010    0.003444    0.009205    0.003387   \nmin      0.005116    0.005192    0.007006   -0.020537   -0.005766    0.006454   \n25%      0.009114    0.008862    0.010195   -0.013892   -0.000709    0.010143   \n50%      0.010601    0.010617    0.012143   -0.011197    0.003977    0.012485   \n75%      0.012328    0.012220    0.013796   -0.009588    0.014261    0.014375   \nmax      0.018116    0.016361    0.019765   -0.005189    0.026665    0.021425   \n\n            Sn_12       Sn_14       Sn_15       Sn_17       Sn_20       Sn_21  \ncount  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000  \nmean    -0.012249    0.005574    0.011670    0.010988   -0.011533   -0.011540  \nstd      0.003736    0.009765    0.002884    0.002383    0.002899    0.002842  \nmin     -0.022150   -0.009362    0.006841    0.006122   -0.019988   -0.019546  \n25%     -0.014874   -0.002402    0.009384    0.009305   -0.013105   -0.013138  \n50%     -0.011462    0.003012    0.011378    0.010961   -0.011151   -0.011283  \n75%     -0.009409    0.012886    0.013416    0.012324   -0.009329   -0.009657  \nmax     -0.005428    0.025416    0.019327    0.016854   -0.006681   -0.005770  \n"
     ]
    }
   ],
   "source": [
    "# Calculate slopes for each column\n",
    "slopes_df, slopes_array = preprocessing.calculate_slopes_all_engines(rul_df, normalised_array)\n",
    "\n",
    "print(slopes_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Slope Order: \n['Sn_11' 'Sn_04' 'Sn_12' 'Sn_07' 'Sn_15' 'Sn_21' 'Sn_20' 'Sn_17' 'Sn_02'\n 'Sn_03' 'Sn_09' 'Sn_14']\n"
     ]
    }
   ],
   "source": [
    "# Order slopes by value\n",
    "slope_order = preprocessing.return_data_ordered_abs_value(slopes_array, rul_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise slopes for each reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not influential: ['Sn_21' 'Sn_20' 'Sn_17' 'Sn_02' 'Sn_03' 'Sn_09' 'Sn_14']\n"
     ]
    }
   ],
   "source": [
    "# Determine [5] most influential columns\n",
    "data_columns = rul_df.columns.values[1:-1]\n",
    "\n",
    "slope_slice = slope_order[5:]\n",
    "\n",
    "data_columns_not_influential = data_columns[slope_slice]\n",
    "\n",
    "print(\"Not influential:\", data_columns_not_influential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        Cycles    Sn_04   Sn_07  Sn_11   Sn_12   Sn_15    RUL\nEngine                                                       \n1            1  1400.60  554.36  47.47  521.66  8.4195 -191.0\n1            2  1403.14  553.75  47.49  522.28  8.4318 -190.0\n1            3  1404.20  554.26  47.27  522.42  8.4178 -189.0\n1            4  1401.87  554.45  47.13  522.86  8.3682 -188.0\n1            5  1406.22  554.00  47.28  522.19  8.4294 -187.0\n...        ...      ...     ...    ...     ...     ...    ...\n100        196  1428.63  551.43  48.07  519.49  8.4956   -4.0\n100        197  1433.58  550.86  48.04  519.68  8.5139   -3.0\n100        198  1428.18  550.94  48.09  520.01  8.5646   -2.0\n100        199  1426.53  550.68  48.39  519.67  8.5389   -1.0\n100        200  1432.14  550.79  48.20  519.30  8.5036    0.0\n\n[20631 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove least influential columns\n",
    "rul_df = preprocessing.dataset_remove_columns(rul_df, data_columns_not_influential)\n",
    "\n",
    "print(rul_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          Sn_04   Sn_07  Sn_11   Sn_12   Sn_15    RUL\nEngine                                               \n1       1400.60  554.36  47.47  521.66  8.4195 -191.0\n1       1403.14  553.75  47.49  522.28  8.4318 -190.0\n1       1404.20  554.26  47.27  522.42  8.4178 -189.0\n1       1401.87  554.45  47.13  522.86  8.3682 -188.0\n1       1406.22  554.00  47.28  522.19  8.4294 -187.0\n...         ...     ...    ...     ...     ...    ...\n100     1428.63  551.43  48.07  519.49  8.4956   -4.0\n100     1433.58  550.86  48.04  519.68  8.5139   -3.0\n100     1428.18  550.94  48.09  520.01  8.5646   -2.0\n100     1426.53  550.68  48.39  519.67  8.5389   -1.0\n100     1432.14  550.79  48.20  519.30  8.5036    0.0\n\n[20631 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove engine cycles (Considered too close to RUL)\n",
    "cycles = ['Cycles']\n",
    "rul_df = preprocessing.dataset_remove_columns(rul_df, cycles)\n",
    "\n",
    "print(rul_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pickling dataframe ...\nPickled dataframe to: C:/Developer/nasa-turbofan-failure-prediction/Data/Interim/rul_dataset_preprocessed.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save dataset\n",
    "filename = 'rul_dataset_preprocessed'\n",
    "data_load.pickle_data(rul_df, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 20631\nTraining Data Items: 16505\nEvaluation Data Items: 4126\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and evaluation sets\n",
    "training_set, evaluation_set = split_data.split_train_eval(rul_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1408.38    553.06     47.57    521.34      8.4225]\n [1421.3     551.73     48.13    519.87      8.4914]\n [1394.82    554.22     47.01    522.16      8.4054]\n ...\n [1405.88    553.37     47.47    521.1       8.4248]\n [1414.14    553.62     47.4     521.37      8.4602]\n [1399.82    554.85     47.36    521.57      8.4335]]\n[-135.   -2. -217. ... -103. -121. -104.]\n"
     ]
    }
   ],
   "source": [
    "# Create RUL Target Dataset\n",
    "\n",
    "# Training Set as Array\n",
    "rul_training_data = training_set.drop('RUL', axis = 1).values\n",
    "rul_training_label = training_set['RUL'].copy().values\n",
    "\n",
    "#print(rul_training_data)\n",
    "#print(rul_training_label)\n",
    "\n",
    "# Evaluation Set as Array\n",
    "rul_eval_data = evaluation_set.drop('RUL', axis = 1).values\n",
    "rul_eval_label = evaluation_set['RUL'].copy().values\n",
    "\n",
    "print(rul_eval_data)\n",
    "print(rul_eval_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinReg_RUL rmse mean (cv): 47.0090594599703\n",
      "LinReg_RUL rmse std (cv): 0.387571187210606\n",
      "LinReg_RUL mae mean (cv): 35.77331902605233\n",
      "LinReg_RUL mae std (cv): 0.2870136374160433\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model (Target - RUL)\n",
    "lin_reg_rul = LinearRegression()\n",
    "model_name = \"LinReg_RUL\"\n",
    "\n",
    "# Train model\n",
    "lin_reg_rul.fit(rul_training_data, rul_training_label)\n",
    "\n",
    "# Save model\n",
    "\n",
    "# Compute RMSE via cross validation\n",
    "scores_mse = cross_val_score(lin_reg_rul, rul_training_data, rul_training_label, scoring = \"neg_mean_squared_error\", cv = 5)\n",
    "scores_rmse = np.sqrt(-scores_mse)\n",
    "\n",
    "# Compute MAE via cross validation\n",
    "scores_mae = cross_val_score(lin_reg_rul, rul_training_data, rul_training_label, scoring = \"neg_mean_absolute_error\", cv = 5)\n",
    "scores_mae = -1 * scores_mae\n",
    "\n",
    "# Visualise cross validation results\n",
    "print(model_name, \"rmse mean (cv):\", scores_rmse.mean())\n",
    "print(model_name, \"rmse std (cv):\", scores_rmse.std())\n",
    "\n",
    "print(model_name, \"mae mean (cv):\", scores_mae.mean())\n",
    "print(model_name, \"mae std (cv):\", scores_mae.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SN_04:  1.5116678520113467\nSN_07:  -8.954735880044808\nSN_11:  59.270500570928334\nSN_12:  -12.218682619970426\nSN_15:  230.45266670228798\nLinReg_RUL rmse (Eval): 46.3992179965504\nLinReg_RUL mae (Eval): 35.69863538647874\nLinReg_RUL r2 (Eval): 0.5287457275816501\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation - Lin Reg RUL\n",
    "\n",
    "# Describe model coefficients\n",
    "print(\"SN_04: \", lin_reg_rul.coef_[0])\n",
    "print(\"SN_07: \", lin_reg_rul.coef_[1])\n",
    "print(\"SN_11: \", lin_reg_rul.coef_[2])\n",
    "print(\"SN_12: \", lin_reg_rul.coef_[3])\n",
    "print(\"SN_15: \", lin_reg_rul.coef_[4])\n",
    "\n",
    "# Evaluate model\n",
    "rul_prediction = lin_reg_rul.predict(rul_eval_data)\n",
    "evaluation.evaluate_model(model_name, rul_eval_label, rul_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}