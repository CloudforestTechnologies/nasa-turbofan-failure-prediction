{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3f92393cf9312ed24f4ccae2fdf5dee1635074d2034ccfaec2d070f8b1ae4f04"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Modules\n",
    "from Source.Data import ntfp_dataset_import as data_load\n",
    "from Source.Data import ntfp_split_data as split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_MODELS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\nLoading pickled dataframe complete ...\n        Cycles   Sn_02    Sn_03    Sn_04   Sn_07    Sn_09  Sn_11   Sn_12  \\\nEngine                                                                     \n1            1  641.82  1589.70  1400.60  554.36  9046.19  47.47  521.66   \n1            2  642.15  1591.82  1403.14  553.75  9044.07  47.49  522.28   \n1            3  642.35  1587.99  1404.20  554.26  9052.94  47.27  522.42   \n1            4  642.35  1582.79  1401.87  554.45  9049.48  47.13  522.86   \n1            5  642.37  1582.85  1406.22  554.00  9055.15  47.28  522.19   \n...        ...     ...      ...      ...     ...      ...    ...     ...   \n100        196  643.49  1597.98  1428.63  551.43  9065.52  48.07  519.49   \n100        197  643.54  1604.50  1433.58  550.86  9065.11  48.04  519.68   \n100        198  643.42  1602.46  1428.18  550.94  9065.90  48.09  520.01   \n100        199  643.23  1605.26  1426.53  550.68  9073.72  48.39  519.67   \n100        200  643.85  1600.38  1432.14  550.79  9061.48  48.20  519.30   \n\n          Sn_14   Sn_15  Sn_17  Sn_20    Sn_21    RUL  \nEngine                                                 \n1       8138.62  8.4195    392  39.06  23.4190 -191.0  \n1       8131.49  8.4318    392  39.00  23.4236 -190.0  \n1       8133.23  8.4178    390  38.95  23.3442 -189.0  \n1       8133.83  8.3682    392  38.88  23.3739 -188.0  \n1       8133.80  8.4294    393  38.90  23.4044 -187.0  \n...         ...     ...    ...    ...      ...    ...  \n100     8137.60  8.4956    397  38.49  22.9735   -4.0  \n100     8136.50  8.5139    395  38.30  23.1594   -3.0  \n100     8141.05  8.5646    398  38.44  22.9333   -2.0  \n100     8139.29  8.5389    395  38.29  23.0640   -1.0  \n100     8137.33  8.5036    396  38.37  23.0522    0.0  \n\n[20631 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset (Use set from previous ML investigation)\n",
    "filename = 'rul_dataset.pkl'\n",
    "rul_df = data_load.load_pickled_data(filename)\n",
    "\n",
    "print(rul_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 20631\nTraining Data Items: 16505\nEvaluation Data Items: 4126\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and evaluation sets\n",
    "training_set, evaluation_set = split_data.split_train_eval(rul_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}