{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3f92393cf9312ed24f4ccae2fdf5dee1635074d2034ccfaec2d070f8b1ae4f04"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sklearn: 0.22.2.post1\nkeras version:  2.4.0\ntensorflow version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Module Importations\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Module Versioning\n",
    "print('sklearn: ' + sklearn.__version__)\n",
    "print('keras version: ', keras.__version__)\n",
    "print('tensorflow version: ', tf.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[keras_helpers]Tensorflow version: 2.4.1\n[keras_helpers]keras version = 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Custom Modules\n",
    "from Source.Data import ntfp_dataset_import as data_load\n",
    "from Source.Data import ntfp_split_data as split_data\n",
    "from Source.Model import ntfp_keras_helpers as keras_helpers\n",
    "from Source.Model import ntfp_model_evaluation as evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_MODELS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading pickled dataframe started ...\nLoading pickled dataframe complete ...\n        Cycles   Sn_02    Sn_03    Sn_04   Sn_07    Sn_09  Sn_11   Sn_12  \\\nEngine                                                                     \n1            1  641.82  1589.70  1400.60  554.36  9046.19  47.47  521.66   \n1            2  642.15  1591.82  1403.14  553.75  9044.07  47.49  522.28   \n1            3  642.35  1587.99  1404.20  554.26  9052.94  47.27  522.42   \n1            4  642.35  1582.79  1401.87  554.45  9049.48  47.13  522.86   \n1            5  642.37  1582.85  1406.22  554.00  9055.15  47.28  522.19   \n...        ...     ...      ...      ...     ...      ...    ...     ...   \n100        196  643.49  1597.98  1428.63  551.43  9065.52  48.07  519.49   \n100        197  643.54  1604.50  1433.58  550.86  9065.11  48.04  519.68   \n100        198  643.42  1602.46  1428.18  550.94  9065.90  48.09  520.01   \n100        199  643.23  1605.26  1426.53  550.68  9073.72  48.39  519.67   \n100        200  643.85  1600.38  1432.14  550.79  9061.48  48.20  519.30   \n\n          Sn_14   Sn_15  Sn_17  Sn_20    Sn_21    RUL  \nEngine                                                 \n1       8138.62  8.4195    392  39.06  23.4190 -191.0  \n1       8131.49  8.4318    392  39.00  23.4236 -190.0  \n1       8133.23  8.4178    390  38.95  23.3442 -189.0  \n1       8133.83  8.3682    392  38.88  23.3739 -188.0  \n1       8133.80  8.4294    393  38.90  23.4044 -187.0  \n...         ...     ...    ...    ...      ...    ...  \n100     8137.60  8.4956    397  38.49  22.9735   -4.0  \n100     8136.50  8.5139    395  38.30  23.1594   -3.0  \n100     8141.05  8.5646    398  38.44  22.9333   -2.0  \n100     8139.29  8.5389    395  38.29  23.0640   -1.0  \n100     8137.33  8.5036    396  38.37  23.0522    0.0  \n\n[20631 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset (Use set from previous ML investigation)\n",
    "filename = 'rul_dataset.pkl'\n",
    "rul_df = data_load.load_pickled_data(filename)\n",
    "\n",
    "print(rul_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Data Items: 20631\nTraining Data Items: 16505\nEvaluation Data Items: 4126\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and evaluation sets\n",
    "training_set, evaluation_set = split_data.split_train_eval(rul_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16505, 13) (16505,)\n(4126, 13) (4126,)\n"
     ]
    }
   ],
   "source": [
    "# Create RUL Target Dataset\n",
    "\n",
    "# Training Set as Array\n",
    "rul_training_data = training_set.drop('RUL', axis = 1).values\n",
    "rul_training_label = training_set['RUL'].copy().values\n",
    "\n",
    "print(rul_training_data.shape, rul_training_label.shape)\n",
    "\n",
    "# Evaluation Set as Array\n",
    "rul_eval_data = evaluation_set.drop('RUL', axis = 1).values\n",
    "rul_eval_label = evaluation_set['RUL'].copy().values\n",
    "\n",
    "print(rul_eval_data.shape, rul_eval_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(13204, 13) (3301, 13)\n",
      "(13204,) (3301,)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(rul_training_data, rul_training_label, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial MLP (Target - RUL)\n",
    "\n",
    "if TRAIN_MODELS == True:\n",
    "    # Clear existing models\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Build model\n",
    "    model = keras_helpers.build_multilayer_perceptron()\n",
    "\n",
    "    # Name model\n",
    "    model_type = \"MLP_RUL\"\n",
    "    model_id = keras_helpers.name_model(model_type)\n",
    "    filepath_full = keras_helpers.make_save_string(model_id)\n",
    "\n",
    "    # Set save and earlystop callbacks\n",
    "    earlystop_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = filepath_full, save_best_only = True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, epochs = 20, validation_data =(X_test, y_test), callbacks =[checkpoint_cb, earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 6)                 84        \n_________________________________________________________________\ndense_1 (Dense)              (None, 6)                 42        \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 7         \n=================================================================\nTotal params: 133\nTrainable params: 133\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (13!=1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3f8dd12dbb93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Determine model prediction stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"MLP_RUL\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrul_eval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrul_pred_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Calculate indicative accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Developer\\nasa-turbofan-failure-prediction\\Source\\Model\\ntfp_model_evaluation.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model_name, y_true, y_pred)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# Calculate performance metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mrmse_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_rmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0mmae_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_mae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mr2_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_r2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Developer\\nasa-turbofan-failure-prediction\\Source\\Model\\ntfp_model_evaluation.py\u001b[0m in \u001b[0;36mevaluate_rmse\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \"\"\"\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mmse_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mrmse_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developer\\Python\\Python366\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \"\"\"\n\u001b[0;32m    251\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 252\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    253\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32mC:\\Developer\\Python\\Python366\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[1;32m---> 96\u001b[1;33m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (13!=1)"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP Model\n",
    "\n",
    "if TRAIN_MODELS == False:\n",
    "    filepath_full = r'C:\\Developer\\nasa-turbofan-failure-prediction\\Models\\PM_MLP_RUL_2021_03_10-10_40_08.h5'\n",
    "\n",
    "# Load model\n",
    "model = keras.models.load_model(filepath_full)\n",
    "\n",
    "# Summarise model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions\n",
    "rul_pred_eval = model.predict(rul_eval_data)\n",
    "\n",
    "# Determine model prediction stats\n",
    "model_name = \"MLP_RUL\"\n",
    "evaluation.evaluate_model(model_name, rul_eval_data, rul_pred_eval)\n",
    "\n",
    "# Calculate indicative accuracy\n",
    "rmse, mae, r2 = model_evaluation.return_model_evaluation_stats(rul_eval_label, rul_pred_eval)"
   ]
  }
 ]
}